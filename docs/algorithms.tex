% Algorithm Listings for Optimizers
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}

\begin{document}

% Traditional DE Algorithm
\begin{algorithm}
\caption{Differential Evolution (DE)}
\begin{algorithmic}[1]
\State Set generation counter $G = 0$
\State Initialize parameters $\beta$ (scale factor) and $CR$ (crossover rate)
\State Create initial population $P$ of $NP$ individuals
\While{stopping condition not met}
    \For{each individual $X_i$ in population}
        \State Evaluate fitness $f(X_i)$
        \State Select random indices $r_1$, $r_2$, $r_3$ â‰  $i$
        \State Create donor vector $V_i = X_{r1} + \beta(X_{r2} - X_{r3})$
        \State Create trial vector $U_i$ via binomial crossover
        \If{$f(U_i)$ better than $f(X_i)$}
            \State Add $U_i$ to next generation
        \Else
            \State Retain $X_i$ in next generation
        \EndIf
    \EndFor
    \State $G = G + 1$
\EndWhile
\State \Return Best individual found
\end{algorithmic}
\end{algorithm}

% PSO Algorithm
\begin{algorithm}
\caption{Particle Swarm Optimization (PSO)}
\begin{algorithmic}[1]
\State Initialize swarm of $n_s$ particles with random positions and velocities
\While{stopping condition not met}
    \For{each particle $i$ in swarm}
        \If{$f(x_i) < f(p_i)$}
            \State Update personal best: $p_i = x_i$
        \EndIf
        \If{$f(p_i) < f(g)$}
            \State Update global best: $g = p_i$
        \EndIf
    \EndFor
    \For{each particle $i$ in swarm}
        \State Update velocity: $v_i = w v_i + c_1r_1(p_i - x_i) + c_2r_2(g - x_i)$
        \State Update position: $x_i = x_i + v_i$
    \EndFor
\EndWhile
\State \Return Global best position $g$
\end{algorithmic}
\end{algorithm}

% Surrogate Optimizer
\begin{algorithm}
\caption{Surrogate-Assisted Optimization}
\begin{algorithmic}[1]
\State Initialize archive $A$ with initial samples
\State Train initial surrogate model $S$ on archive
\While{budget not exhausted}
    \State Select promising candidates $C$ using acquisition function
    \For{each candidate $x$ in $C$}
        \State Evaluate true fitness $f(x)$
        \State Add $(x, f(x))$ to archive $A$
    \EndFor
    \State Update surrogate model $S$ using archive $A$
    \State Update acquisition function parameters
\EndWhile
\State \Return Best solution from archive $A$
\end{algorithmic}
\end{algorithm}

% Meta Optimizer
\begin{algorithm}
\caption{Meta-Optimizer}
\begin{algorithmic}[1]
\State Initialize optimizer pool $O = \{O_1, ..., O_k\}$
\State Initialize problem analyzer $PA$
\State Initialize selection history $H$
\While{stopping condition not met}
    \State Extract problem features $F$ using $PA$
    \State Calculate optimizer scores $S$ based on $H$ and $F$
    \State Select best optimizer $O_i$ based on scores $S$
    \For{$t = 1$ to $T$ iterations}
        \State Run selected optimizer $O_i$ for one step
        \State Update performance history $H$
        \If{convergence detected}
            \State Break
        \EndIf
    \EndFor
    \State Update optimizer selection strategy
\EndWhile
\State \Return Best solution found
\end{algorithmic}
\end{algorithm}

% ACO Algorithm
\begin{algorithm}
\caption{Ant Colony Optimization (ACO)}
\begin{algorithmic}[1]
\State Initialize pheromone trails $\tau_{ij}$ and heuristic information $\eta_{ij}$
\While{stopping condition not met}
    \For{each ant $k = 1$ to $m$}
        \State Construct solution using probability:
        \State $p_{ij}^k = \frac{[\tau_{ij}]^\alpha[\eta_{ij}]^\beta}{\sum_{l\in N_i^k}[\tau_{il}]^\alpha[\eta_{il}]^\beta}$
    \EndFor
    \State Update pheromone trails:
    \State $\tau_{ij} = (1-\rho)\tau_{ij} + \sum_{k=1}^m \Delta\tau_{ij}^k$
    \State Apply local search (optional)
\EndWhile
\State \Return Best solution found
\end{algorithmic}
\end{algorithm}

% GWO Algorithm
\begin{algorithm}
\caption{Grey Wolf Optimizer (GWO)}
\begin{algorithmic}[1]
\State Initialize wolf population
\While{stopping condition not met}
    \State Sort wolves based on fitness
    \State Assign $\alpha$, $\beta$, and $\delta$ wolves
    \For{each wolf}
        \State Update position using:
        \State $\vec{X}(t+1) = \frac{\vec{X_1} + \vec{X_2} + \vec{X_3}}{3}$
        \Where
        \State $\vec{X_1} = |\vec{X_\alpha} - \vec{A_1}\cdot\vec{D_\alpha}|$
        \State $\vec{X_2} = |\vec{X_\beta} - \vec{A_2}\cdot\vec{D_\beta}|$
        \State $\vec{X_3} = |\vec{X_\delta} - \vec{A_3}\cdot\vec{D_\delta}|$
    \EndFor
    \State Update $a$, $A$, and $C$ parameters
\EndWhile
\State \Return Best solution ($\alpha$ wolf position)
\end{algorithmic}
\end{algorithm}

% ES Algorithm
\begin{algorithm}
\caption{Evolution Strategy (ES)}
\begin{algorithmic}[1]
\State Initialize parent population of $\mu$ individuals
\While{stopping condition not met}
    \For{$i = 1$ to $\lambda$}
        \State Select parents using tournament selection
        \State Create offspring via recombination
        \State Apply mutation with self-adaptive step size
        \State Evaluate offspring fitness
    \EndFor
    \State Select best $\mu$ individuals for next generation
    \State Update strategy parameters
\EndWhile
\State \Return Best individual found
\end{algorithmic}
\end{algorithm}

\end{document}
